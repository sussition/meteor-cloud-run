const fs = require('fs-extra');
const path = require('path');
const crypto = require('crypto');
const { detectMeteorVersion, getCompatibleBaseImage, getServiceName, getSecretName } = require('./utils');

async function createDeploymentFiles(config, mongoUrl) {
  // Create the .meteor-cloud-run directory
  const deployDir = '.meteor-cloud-run';
  await fs.ensureDir(deployDir);

  // Save clean configuration without any secrets or settings content
  const cleanConfig = { ...config };
  delete cleanConfig.meteorSettings; // Remove any temporary secrets
  delete cleanConfig.rawSettings; // Never save raw settings to disk
  await fs.writeJson(path.join(deployDir, 'config.json'), cleanConfig, { spaces: 2 });

  // Detect Meteor version and get compatible base image
  const meteorVersion = await detectMeteorVersion();
  const defaultVersion = '2.12';
  const finalVersion = meteorVersion || defaultVersion;
  
  if (!meteorVersion) {
    console.log(require('chalk').yellow(`⚠️ Could not detect Meteor version, using default version ${defaultVersion}`));
  }
  
  // Don't log here - it's already logged in commands.js during init
  
  const baseImage = await getCompatibleBaseImage(finalVersion);
  console.log(require('chalk').blue(`🐳 Using base image: ${baseImage}`));

  // Generate Dockerfile
  await createDockerfile(baseImage);
  
  // Generate startup script
  await createStartupScript();
  
  // Generate .dockerignore
  await createDockerignore();
  
  // Generate cloudbuild.yaml
  await createCloudBuildConfig(config, mongoUrl);
}

async function createDockerfile(baseImage) {
  const dockerfile = `# Build stage
FROM ${baseImage} as builder

# Copy app files
COPY . /app

# Build the app
RUN cd /app && \\
    meteor npm install && \\
    meteor build --directory /opt/bundle --server-only

# Production stage
FROM node:18-slim

# Copy the built app
COPY --from=builder /opt/bundle/bundle /app

# Install production dependencies
WORKDIR /app/programs/server
RUN npm install

# Set up environment
WORKDIR /app
ENV PORT=8080

# Install curl and jq for GCS access
RUN apt-get update && apt-get install -y curl jq && apt-get clean && rm -rf /var/lib/apt/lists/*

# Create startup script
COPY .meteor-cloud-run/meteor-cloud-run-startup.sh /meteor-cloud-run-startup.sh
RUN chmod +x /meteor-cloud-run-startup.sh

# Start the app
CMD ["/meteor-cloud-run-startup.sh"]`;

  // Ensure consistent Unix line endings for cross-platform compatibility
  await fs.writeFile(path.join('.meteor-cloud-run', 'Dockerfile'), dockerfile.replace(/\r\n/g, '\n').replace(/\r/g, '\n'));
}

async function createStartupScript() {
  const startupScript = `#!/bin/bash
# This file is automatically generated by Meteor Cloud Run
# Do not edit this file manually - it will be overwritten on next deployment
#
# Meteor Cloud Run startup script (meteor-cloud-run-startup.sh) for Meteor applications on Google Cloud Run
# Handles METEOR_SETTINGS download from Google Cloud Storage

set -e

echo 'Starting Meteor app...'

if [ ! -z "$METEOR_SETTINGS_GCS_BUCKET" ] && [ ! -z "$METEOR_SETTINGS_GCS_FILE" ]; then
    echo 'Downloading METEOR_SETTINGS from GCS...'
    echo 'Getting access token...'
    
    TOKEN=$(curl -s -H 'Metadata-Flavor: Google' 'http://metadata.google.internal/computeMetadata/v1/instance/service-accounts/default/token' | jq -r '.access_token')
    
    if [ -z "$TOKEN" ] || [ "$TOKEN" = "null" ]; then
        echo 'ERROR: Failed to get access token'
        exit 1
    fi
    
    echo 'Token obtained, downloading settings...'
    
    if curl -s -H "Authorization: Bearer $TOKEN" "https://storage.googleapis.com/$METEOR_SETTINGS_GCS_BUCKET/$METEOR_SETTINGS_GCS_FILE" > /tmp/settings.json; then
        if [ -s /tmp/settings.json ]; then
            echo 'Validating JSON format...'
            if jq empty /tmp/settings.json 2>/dev/null; then
                echo 'JSON validation passed'
                # Properly quote the JSON content to prevent shell interpretation
                export METEOR_SETTINGS="$(cat /tmp/settings.json)"
                rm /tmp/settings.json
                echo 'METEOR_SETTINGS loaded successfully'
                echo "METEOR_SETTINGS length: \${#METEOR_SETTINGS}"
            else
                echo 'ERROR: Downloaded file is not valid JSON'
                echo 'File contents:'
                cat /tmp/settings.json
                exit 1
            fi
        else
            echo 'ERROR: Downloaded settings file is empty'
            exit 1
        fi
    else
        echo 'ERROR: Failed to download settings from GCS'
        exit 1
    fi
else
    echo 'No GCS settings configured'
fi

echo 'Starting Node.js...'
exec node main.js
`;

  // Ensure consistent Unix line endings for cross-platform compatibility
  await fs.writeFile(path.join('.meteor-cloud-run', 'meteor-cloud-run-startup.sh'), startupScript.replace(/\r\n/g, '\n').replace(/\r/g, '\n'));
}

async function createDockerignore() {
  const dockerignore = `.meteor/local
node_modules`;
  // Ensure consistent Unix line endings for cross-platform compatibility
  await fs.writeFile(path.join('.meteor-cloud-run', '.dockerignore'), dockerignore.replace(/\r\n/g, '\n').replace(/\r/g, '\n'));
}

async function createCloudBuildConfig(config, mongoUrl, settingsInfo = null) {
  const serviceName = getServiceName(config);
  // Separate sensitive and non-sensitive variables
  let envVars = [`ROOT_URL=${config.rootUrl || 'https://placeholder.run.app'}`];
  let secrets = [];
  
  // Non-sensitive environment variables
  if (config.httpForwardedCount) {
    envVars.push(`HTTP_FORWARDED_COUNT=${config.httpForwardedCount}`);
  }
  
  if (config.disableWebsockets) {
    envVars.push(`DISABLE_WEBSOCKETS=${config.disableWebsockets}`);
  }
  
  // Add all additional environment variables from Galaxy or other sources
  if (config.additionalEnvVars) {
    Object.entries(config.additionalEnvVars).forEach(([key, value]) => {
      envVars.push(`${key}=${value}`);
    });
  }
  
  // Sensitive variables - always use secrets for security
  const secretsToCreate = [];
  
  if (mongoUrl) {
    const secretName = getSecretName(serviceName, 'mongodb-url');
    secretsToCreate.push({ name: secretName, value: mongoUrl, envName: 'MONGO_URL' });
    secrets.push(`MONGO_URL=${secretName}:latest`);
  }
  
  if (config.mongoOplogUrl) {
    const secretName = getSecretName(serviceName, 'mongodb-oplog-url');
    secretsToCreate.push({ name: secretName, value: config.mongoOplogUrl, envName: 'MONGO_OPLOG_URL' });
    secrets.push(`MONGO_OPLOG_URL=${secretName}:latest`);
  }
  
  if (config.mailUrl) {
    const secretName = getSecretName(serviceName, 'mail-url');
    secretsToCreate.push({ name: secretName, value: config.mailUrl, envName: 'MAIL_URL' });
    secrets.push(`MAIL_URL=${secretName}:latest`);
  }
  
  // Add METEOR_SETTINGS via pre-created GCS bucket (if provided)
  if (settingsInfo) {
    envVars.push(`METEOR_SETTINGS_GCS_BUCKET=${settingsInfo.bucket}`);
    envVars.push(`METEOR_SETTINGS_GCS_FILE=${settingsInfo.file}`);
  }
  
  // Build deployment arguments
  let deployArgs = [];
  if (envVars.length > 0) {
    deployArgs.push(`--set-env-vars=${envVars.join(',')}`);
  }
  if (secrets.length > 0) {
    deployArgs.push(`--update-secrets=${secrets.join(',')}`);
  }
  
  // Add VPC connector if configured (for static outbound IP)
  if (config.loadBalancerResources && config.loadBalancerResources.vpcConnectorName) {
    deployArgs.push(`--vpc-connector=${config.loadBalancerResources.vpcConnectorName}`);
    deployArgs.push(`--vpc-egress=all-traffic`);
  } else if (config.createStaticOutboundIp && config.region) {
    // If static outbound IP is requested but VPC connector doesn't exist yet,
    // it will be created after deployment and Cloud Run will be updated
    console.log('Note: VPC connector will be configured after initial deployment');
  }

  const cloudbuild = `steps:
  # Create Artifact Registry repository if it doesn't exist
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        gcloud artifacts repositories create ${serviceName} --repository-format=docker --location=${config.region} --quiet || true
${secretsToCreate.length > 0 ? `
  # Optimize secret management to reduce costs
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        # Enable Secret Manager API
        gcloud services enable secretmanager.googleapis.com
        
        # Get the actual project number for the service account
        PROJECT_NUMBER=$$(gcloud projects describe $PROJECT_ID --format="value(projectNumber)")
        echo "Project number: $$PROJECT_NUMBER"
        
        if [ -z "$$PROJECT_NUMBER" ]; then
          echo "ERROR: Could not get project number for service account"
          exit 1
        fi
        
        # Grant permissions to the default compute service account
        SERVICE_ACCOUNT="$$PROJECT_NUMBER-compute@developer.gserviceaccount.com"
        echo "Service account: $$SERVICE_ACCOUNT"
        
${secretsToCreate.map(secret => `        
        # Optimized handling for ${secret.name} secret
        # Only create new version if value has changed
        CURRENT_VALUE=""
        if gcloud secrets describe ${secret.name} --project=$PROJECT_ID >/dev/null 2>&1; then
          echo "Secret ${secret.name} exists, checking if update needed..."
          CURRENT_VALUE=$$(gcloud secrets versions access latest --secret=${secret.name} --project=$PROJECT_ID 2>/dev/null || echo "")
          
          if [ "$$CURRENT_VALUE" = "$_${secret.envName}" ]; then
            echo "✅ Secret ${secret.name} unchanged, skipping version creation (cost optimization)"
          else
            echo "Secret value changed, creating new version..."
            echo -n "$_${secret.envName}" | gcloud secrets versions add ${secret.name} --data-file=- --project=$PROJECT_ID
            
            # Cleanup old versions to reduce costs (keep only 3 most recent)
            echo "Cleaning up old versions..."
            VERSIONS=$$(gcloud secrets versions list ${secret.name} --project=$PROJECT_ID --filter="state:ENABLED" --format="value(name)" | tail -n +4)
            for VERSION in $$VERSIONS; do
              VERSION_ID=$$(echo $$VERSION | rev | cut -d'/' -f1 | rev)
              gcloud secrets versions destroy $$VERSION_ID --secret=${secret.name} --project=$PROJECT_ID --quiet || true
            done
          fi
        else
          echo "Creating new secret ${secret.name}..."
          echo -n "$_${secret.envName}" | gcloud secrets create ${secret.name} --data-file=- --project=$PROJECT_ID --replication-policy=automatic
        fi
        
        # Grant IAM permissions - retry up to 3 times to ensure it works
        echo "Granting secret access to service account..."
        for i in 1 2 3; do
          if gcloud secrets add-iam-policy-binding ${secret.name} \
            --member="serviceAccount:$$SERVICE_ACCOUNT" \
            --role="roles/secretmanager.secretAccessor" \
            --project=$PROJECT_ID 2>/dev/null; then
            echo "✅ Secret permissions granted successfully"
            break
          else
            echo "Attempt $$i failed, retrying..."
            sleep 2
          fi
        done`).join('')}
        
        echo "Secret management completed with cost optimization"` : ''}
  
  # Configure docker to authenticate with Artifact Registry
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: 'bash'
    args:
      - '-c'
      - |
        gcloud auth configure-docker ${config.region}-docker.pkg.dev --quiet
  
  # Build the container image
  - name: 'gcr.io/cloud-builders/docker'
    args: ['build', '-f', '.meteor-cloud-run/Dockerfile', '-t', '${config.region}-docker.pkg.dev/$PROJECT_ID/${serviceName}/${serviceName}:latest', '.']
  
  # Push the container image to Artifact Registry
  - name: 'gcr.io/cloud-builders/docker'
    args: ['push', '${config.region}-docker.pkg.dev/$PROJECT_ID/${serviceName}/${serviceName}:latest']
  
  # Deploy container image to Cloud Run
  - name: 'gcr.io/google.com/cloudsdktool/cloud-sdk'
    entrypoint: bash
    args:
      - '-c'
      - |
        # Deploy to Cloud Run (using default compute service account)
        # Using --allow-unauthenticated for public access through load balancer
        # This flag configures the service differently than IAM bindings
        gcloud run deploy ${serviceName} \\
          --image=${config.region}-docker.pkg.dev/$PROJECT_ID/${serviceName}/${serviceName}:latest \\
          --platform=managed \\
          --region=${config.region} \\
          --allow-unauthenticated \\
          --ingress=all \\
${deployArgs.map(arg => '          ' + arg + ' \\').join('\n')}${deployArgs.length > 0 ? '\n' : ''}          --cpu=${config.cpu} \\
          --memory=${config.memory} \\
          --concurrency=${config.concurrency} \\
          --min-instances=${config.minInstances} \\
          --max-instances=${config.maxInstances} \\
          --port=8080

images:
  - '${config.region}-docker.pkg.dev/$PROJECT_ID/${serviceName}/${serviceName}:latest'`;

  // Ensure consistent Unix line endings for cross-platform compatibility
  const cloudbuildUnix = cloudbuild.replace(/\r\n/g, '\n').replace(/\r/g, '\n');
  await fs.writeFile(path.join('.meteor-cloud-run', 'cloudbuild.yaml'), cloudbuildUnix);
}

// Helper function to create a persistent GCS bucket and upload settings
async function uploadSettingsToGCS(projectId, settingsData) {
  const { executeCommand, getServiceName } = require('./utils');
  const timestamp = Date.now();
  const bucketName = `meteor-cloud-run-settings-${projectId}`;
  const fileName = `settings-${timestamp}.json`; // Timestamped filename for proper rollback

  try {
    console.log(require('chalk').blue('📦 Using persistent GCS bucket for settings...'));

    // Get project number for service account
    const projectNumberResult = await executeCommand(`gcloud projects describe ${projectId} --format="value(projectNumber)"`);
    const projectNumber = projectNumberResult.stdout.trim();

    if (!projectNumber) {
      throw new Error(`Could not get project number for project ${projectId}`);
    }

    // Create persistent bucket if it doesn't exist
    try {
      await executeCommand(`gsutil mb gs://${bucketName}`);
      console.log(require('chalk').green('✅ Created persistent settings bucket'));
    } catch (error) {
      if (error.message.includes('already exists')) {
        console.log(require('chalk').blue('📦 Using existing persistent settings bucket'));
      } else {
        throw error;
      }
    }

    // Set lifecycle policy with dual protection:
    // Rule 1: Delete if there are more than 5 newer versions (keeps recent 5 files)
    // Rule 2: Delete if older than 90 days AND there's at least 1 newer version (prevents last file deletion)
    // This ensures:
    //   - Active deployments are safe (always keeps 5 recent files)
    //   - Old unused files are cleaned up after 90 days
    //   - Never deletes the last remaining file
    const lifecyclePolicy = JSON.stringify({
      lifecycle: {
        rule: [
          {
            action: { type: "Delete" },
            condition: {
              numNewerVersions: 5  // Keep 5 most recent files (rollback + active deployments)
            }
          },
          {
            action: { type: "Delete" },
            condition: {
              age: 90,  // AND older than 90 days
              numNewerVersions: 1  // AND at least 1 newer file exists (prevents deleting last file)
            }
          }
        ]
      }
    });
    
    // Create secure temporary files with restricted permissions
    const tempDir = await fs.mkdtemp(path.join(require('os').tmpdir(), 'meteor-cloud-run-'));
    const lifecyclePath = path.join(tempDir, 'lifecycle.json');
    const settingsPath = path.join(tempDir, 'settings.json');

    try {
      // Set lifecycle policy only if it doesn't exist or needs updating
      try {
        const currentLifecycle = await executeCommand(`gsutil lifecycle get gs://${bucketName}`);
        const hasCorrectPolicy = currentLifecycle.stdout.includes('numNewerVersions') &&
                                 currentLifecycle.stdout.includes('"age": 90');

        if (!hasCorrectPolicy) {
          await fs.writeFile(lifecyclePath, lifecyclePolicy, { mode: 0o600 });
          await executeCommand(`gsutil lifecycle set ${lifecyclePath} gs://${bucketName}`);
          console.log(require('chalk').green('✅ Updated bucket lifecycle policy'));
        } else {
          console.log(require('chalk').blue('📦 Lifecycle policy already configured'));
        }
      } catch (error) {
        // Set lifecycle policy if it doesn't exist
        await fs.writeFile(lifecyclePath, lifecyclePolicy, { mode: 0o600 });
        await executeCommand(`gsutil lifecycle set ${lifecyclePath} gs://${bucketName}`);
        console.log(require('chalk').green('✅ Set bucket lifecycle policy'));
      }

      // Write settings to secure temporary file and upload (overwrites existing)
      await fs.writeFile(settingsPath, JSON.stringify(settingsData, null, 2), { mode: 0o600 });
      await executeCommand(`gsutil cp ${settingsPath} gs://${bucketName}/${fileName}`);
      console.log(require('chalk').green('✅ Settings uploaded (previous version archived for rollback)'));

      // Set IAM permissions for Cloud Run service account (uses project number, not project ID)
      await executeCommand(`gsutil iam ch serviceAccount:${projectNumber}-compute@developer.gserviceaccount.com:objectViewer gs://${bucketName}`);
    } finally {
      // Secure cleanup of temporary directory and all contents
      await fs.remove(tempDir);
    }
    
    console.log(require('chalk').green(`✅ Settings uploaded to gs://${bucketName}/${fileName}`));
    
    return {
      bucket: bucketName,
      file: fileName
    };
  } catch (error) {
    console.log(require('chalk').red(`❌ Failed to upload settings to GCS: ${error.message}`));
    throw error;
  }
}

module.exports = {
  createDeploymentFiles,
  createDockerfile,
  createStartupScript,
  createDockerignore,
  createCloudBuildConfig,
  uploadSettingsToGCS
};